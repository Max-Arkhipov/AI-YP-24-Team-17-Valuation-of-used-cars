{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "import random\n",
    "from datetime import date\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "cookie = 'suid=658a8fbbd4d62b52646569d9bd097904.43edb6f93dcf733e401fd573505fae33; yandexuid=6442247681727433546; _ym_uid=1727441690902878709; popups-group-popups-rk-new-shown-count=3; yandex_login=archipovma; L=SnR5B35wUnhZXnkFVA19WH1oSkBedmt8JxZUOT00CzxbEA==.1727848766.15906.375791.46559e905b4ac4a9e202ef3be2b4f5cb; autoru_sid=87804195%7C1727861837914.7776000.FeISZEMMuOB0RWRXQVD6-w.uKhHhSbOwm3q3gT_iJTO8Y-ocbTeNormPvTBNytBGBs; autoru-visits-count=5; fp=aea60bf3d6240d9ce83842d85d939686%7C1728364386979; i=GeBYe5RxnvyiQxUnp7zVFo15irxSAsjTMIs5wDlTnBOM7K+ibvDg6BmPrQzG5edJgj5D3TTWYYUZ5qA+a0gRsJB8n/4=; my=YwA=; gdpr=0; _csrf_token=ec0eaa3de01db2c5942b4ba4cad66009accf66975fdf72b6; autoruuid=g66f6ab0a2mjm7vghno04odnm0emvga4.9478b8f698702cea809903f2e486a958; from=google-search; autoru_sso_blocked=1; _yasc=L9eycavOPcH5oC0mDw/jpTm4amAk1ath7PM4Kv5Ku70mGbZlhxw9U/ki9ND2YGarYTxN7ws=; Session_id=3:1728904843.5.0.1727848766812:CF4quQ:ac57.1.2:1|653439336.-1.2.3:1727848766|61:10026628.853436.IC7iwe7fYdz1fVZX0KVMYVOeLPs; sessar=1.1194.CiCKE-3bpDdAbTIwBdB7VpVcfEXRRsufwppSSMHWXL8rcw.vlw4jo-kTya4nk3xbtxocr-zMGSULTBw76CQmOz9w8o; ys=udn.cDrQnNCw0LrRgdC40Lwg0JDQvdCw0YLQvtC70YzQtdCy0LjRhyDQkNGA0YXQuNC/0L7Qsg%3D%3D#c_chck.3618600067; mda2_beacon=1728904843129; sso_status=sso.passport.yandex.ru:synchronized; autoru_sso_redirect_blocked=1; _ym_d=1728904843; count-visits=1; yaPlusUserPlusBalance={%22id%22:%2287804195%22%2C%22plusPoints%22:240}; _ym_isad=2; yaPassportTryAutologin=1; layout-config={\"screen_height\":1440,\"screen_width\":2560,\"win_width\":1546,\"win_height\":1260}; from_lifetime=1728904867386; cycada=6GiRzZVDG7CoCAVoWBxFFI8yFMQuLFtFitC2v4m+yfw='\n",
    "headers = {\n",
    "    'authority': 'auto.ru',\n",
    "    'method': 'GET',\n",
    "    'path': '/cars/used/',\n",
    "    'scheme': 'https',\n",
    "    'accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7',\n",
    "    'accept-encoding': 'gzip, deflate, br, zstd',\n",
    "    'accept-language': 'ru-RU,ru;q=0.9,en-US;q=0.8,en;q=0.7',\n",
    "    'cookie': cookie,\n",
    "    'priority': 'u=0, i',\n",
    "    'referer': 'https://auto.ru/cars/new/',\n",
    "    'sec-ch-ua': '\"Google Chrome\";v=\"129\", \"Not=A?Brand\";v=\"8\", \"Chromium\";v=\"129\"',\n",
    "    'sec-ch-ua-mobile': '?0',\n",
    "    'sec-ch-ua-platform':'\"Linux\"',\n",
    "    'sec-fetch-dest': 'document',\n",
    "    'sec-fetch-mode': 'navigate',\n",
    "    'sec-fetch-site': 'same-origin',\n",
    "    'sec-fetch-user': '?1',\n",
    "    'upgrade-insecure-requests': '1',\n",
    "    'user-agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/129.0.0.0 Safari/537.36'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sleep():\n",
    "    random_seconds = np.linspace(3, 10, 100)\n",
    "    time.sleep(random.choice(random_seconds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_complectation(link):\n",
    "    url_compl = link # записали ссылку\n",
    "\n",
    "    # Немного подождали\n",
    "    sleep()\n",
    "    \n",
    "    # загрузили страницу с данными по автомобилю\n",
    "    page_compl = requests.get(link, headers=headers)\n",
    "        \n",
    "    # time.sleep(random.choice(random_seconds))\n",
    "    soup_compl = BeautifulSoup(page_compl.content, 'html.parser')\n",
    "\n",
    "    # Нашли нужный блок\n",
    "    card_info = soup_compl.find('div', {'class': 'ModificationInfo-GiDD1'})\n",
    "\n",
    "    # извлекли сведения о комплектации\n",
    "    for li in card_info.find_all('li'):\n",
    "        if 'Страна марки' in li.find('span').text:\n",
    "            state_mark = li.find_all('span')[1].text.replace('\\xa0',' ')\n",
    "        if 'Класс автомобиля' in li.find('span').text:\n",
    "            class_auto = li.find_all('span')[1].text.replace('\\xa0','')\n",
    "        if 'Количество дверей' in li.find('span').text:\n",
    "            door_count = li.find_all('span')[1].text.replace('\\xa0','')\n",
    "        if 'Количество мест' in li.find('span').text:\n",
    "            seat_count = li.find_all('span')[1].text.replace('\\xa0','')\n",
    "        if 'Длина' in li.find('span').text:\n",
    "            long = li.find_all('span')[1].text.replace('\\xa0',' ')\n",
    "        if 'Ширина' in li.find('span').text and 'Ширина ' not in li.find('span').text:\n",
    "            widht = li.find_all('span')[1].text.replace('\\xa0',' ')\n",
    "        if 'Высота' in li.find('span').text:\n",
    "            height = li.find_all('span')[1].text.replace('\\xa0',' ')\n",
    "        if 'Клиренс' in li.find('span').text:\n",
    "            clearence = li.find_all('span')[1].text.replace('\\xa0',' ')\n",
    "        if 'Объем багажника' in li.find('span').text:\n",
    "            v_bag = li.find_all('span')[1].text.replace('\\xa0',' ')\n",
    "        if 'Объём топливного' in li.find('span').text:\n",
    "            v_tank = li.find_all('span')[1].text.replace('\\xa0',' ')\n",
    "        if 'Снаряженная масса' in li.find('span').text:\n",
    "            curb_weight = li.find_all('span')[1].text.replace('\\xa0',' ')        \n",
    "        if 'Полная масса' in li.find('span').text:\n",
    "            gross_weight = li.find_all('span')[1].text.replace('\\xa0',' ')\n",
    "        if 'Передние тормоза' in li.find('span').text:\n",
    "            front_brakes = li.find_all('span')[1].text.replace('\\xa0',' ')\n",
    "        if 'Задние тормоза' in li.find('span').text:\n",
    "            rear_brakes = li.find_all('span')[1].text.replace('\\xa0',' ')\n",
    "        if 'Максимальная скорость' in li.find('span').text:\n",
    "            max_speed = li.find_all('span')[1].text.replace('\\xa0',' ')\n",
    "        if 'Разгон' in li.find('span').text:\n",
    "            acceleration = li.find_all('span')[1].text.replace('\\xa0',' ')\n",
    "        if 'Расход топлива' in li.find('span').text:\n",
    "            fuel_cons = li.find_all('span')[1].text.replace('\\xa0','')\n",
    "        if 'Марка топлива' in li.find('span').text:\n",
    "            fuel_brand = li.find_all('span')[1].text.replace('\\xa0','')\n",
    "        if 'Расположение двигателя' in li.find('span').text:\n",
    "            engine_loc = li.find_all('span')[1].text.replace('\\xa0','')\n",
    "        if 'Тип наддува' in li.find('span').text:\n",
    "            turbocharg = li.find_all('span')[1].text.replace('\\xa0','')\n",
    "        if 'Максимальный крутящий' in li.find('span').text:\n",
    "            max_torq = li.find_all('span')[1].text.replace('\\xa0','')\n",
    "        if 'Количество цилиндров' in li.find('span').text:\n",
    "            cyl_count = li.find_all('span')[1].text.replace('\\xa0','')\n",
    "        \n",
    "    # Проверили данные, при необходимости присвоили None\n",
    "    try:\n",
    "        state_mark = state_mark.replace('\\xa0','')\n",
    "    except:\n",
    "        state_mark = None\n",
    "    try:\n",
    "        class_auto = class_auto.replace('\\xa0','')\n",
    "    except:\n",
    "        class_auto = None\n",
    "    try:\n",
    "        door_count = door_count.replace('\\xa0','')\n",
    "    except:\n",
    "        door_count = None\n",
    "    try:\n",
    "        seat_count = seat_count.replace('\\xa0','')\n",
    "    except:\n",
    "        seat_count = None   \n",
    "    try:\n",
    "        long = long.split()[0]\n",
    "    except:\n",
    "        long = None   \n",
    "    try:\n",
    "        widht = widht.split()[0]\n",
    "    except:\n",
    "        widht = None \n",
    "    try:\n",
    "        height = height.split()[0]\n",
    "    except:\n",
    "        height = None \n",
    "    try:\n",
    "        clearence = clearence.split()[0]\n",
    "    except:\n",
    "        clearence = None \n",
    "    try:\n",
    "        v_bag = v_bag.split()[0]\n",
    "    except:\n",
    "        v_bag = None\n",
    "    try:\n",
    "        v_tank = v_tank.split()[0]\n",
    "    except:\n",
    "        v_tank = None\n",
    "    try:\n",
    "        curb_weight = curb_weight.split()[0]\n",
    "    except:\n",
    "        curb_weight = None\n",
    "    try:\n",
    "        gross_weight = gross_weight.split()[0]\n",
    "    except:\n",
    "        gross_weight = None\n",
    "    try:\n",
    "        front_brakes = front_brakes.split()[0].replace('\\xa0','')\n",
    "    except:\n",
    "        front_brakes = None\n",
    "    try:\n",
    "        rear_brakes = rear_brakes.split()[0].replace('\\xa0','')\n",
    "    except:\n",
    "        rear_brakes = None\n",
    "    try:\n",
    "        max_speed = max_speed.split()[0]\n",
    "    except:\n",
    "        max_speed = None\n",
    "    try:\n",
    "        acceleration = acceleration.split()[0]\n",
    "    except:\n",
    "        acceleration = None\n",
    "    try:\n",
    "        fuel_cons = fuel_cons.split('/')[1]\n",
    "    except:\n",
    "        fuel_cons = None\n",
    "    try:\n",
    "        fuel_brand = fuel_brand.replace('\\xa0','')\n",
    "    except:\n",
    "        fuel_brand = None\n",
    "    try:\n",
    "        engine_loc1 = engine_loc.split(', ')[0]\n",
    "    except:\n",
    "        engine_loc1 = None\n",
    "    try:\n",
    "        engine_loc2 = engine_loc.split(', ')[1]\n",
    "    except:\n",
    "        engine_loc2 = None\n",
    "    try:\n",
    "        turbocharg = turbocharg.replace('\\xa0','')\n",
    "    except:\n",
    "        turbocharg = None\n",
    "    try:\n",
    "        max_torq = max_torq.split()[0]\n",
    "    except:\n",
    "        max_torq = None\n",
    "    try:\n",
    "        cyl_count = cyl_count.replace('\\xa0','')\n",
    "    except:\n",
    "        cyl_count = None\n",
    "\n",
    "    # записали данные в словарь\n",
    "    row = {\n",
    "        'url_compl': url_compl,\n",
    "        'state_mark': state_mark,\n",
    "        'class_auto': class_auto,\n",
    "        'door_count': door_count,\n",
    "        'seat_count': seat_count,\n",
    "        'long': long,\n",
    "        'widht': widht,\n",
    "        'height': height,\n",
    "        'clearence': clearence,\n",
    "        'v_bag': v_bag,\n",
    "        'v_tank': v_tank,\n",
    "        'curb_weight': curb_weight,\n",
    "        'gross_weight': gross_weight,\n",
    "        'front_brakes': front_brakes,\n",
    "        'rear_brakes': rear_brakes,\n",
    "        'max_speed': max_speed,\n",
    "        'acceleration': acceleration,\n",
    "        'fuel_cons': fuel_cons,\n",
    "        'fuel_brand': fuel_brand,\n",
    "        'engine_loc1': engine_loc1,\n",
    "        'engine_loc2': engine_loc2,\n",
    "        'turbocharg': turbocharg,\n",
    "        'max_torq': max_torq,\n",
    "        'cyl_count': cyl_count\n",
    "        }\n",
    "\n",
    "    # передали словарь\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_car(link):    \n",
    "    url_car = link # записали ссылку\n",
    "\n",
    "    # Немного подождали\n",
    "    sleep()\n",
    "\n",
    "    # загрузили страницу с данными по автомобилю\n",
    "    page_auto = requests.get(link, headers=headers)\n",
    "        \n",
    "    # time.sleep(random.choice(random_seconds))\n",
    "    soup_auto = BeautifulSoup(page_auto.content, 'html.parser')\n",
    "\n",
    "    # извлекли данные из блока CardBreadcrumbs\n",
    "    CardBreadcrums = soup_auto.find('div', {'class': 'CardBreadcrumbs'})\n",
    "    car_make = CardBreadcrums.find_all('a')[2].text\n",
    "    car_model = CardBreadcrums.find_all('a')[3].text\n",
    "    car_gen = CardBreadcrums.find_all('a')[4].text\n",
    "    car_type = CardBreadcrums.find_all('a')[5].text\n",
    "    car_compl = CardBreadcrums.find_all('a')[6].text\n",
    "\n",
    "    # извлекли данные об объявлении\n",
    "    ann_date = soup_auto.find('div', {'class': 'CardHead__infoItem CardHead__creationDate'}).text\n",
    "    ann_id = soup_auto.find('div', {'class': 'CardHead__infoItem CardHead__id'}).text\n",
    "    car_price = soup_auto.find('span', {'class': 'OfferPriceCaption__price'}).text.replace('\\xa0','')\n",
    "    ann_city = soup_auto.find('span', {'class': 'MetroListPlace__regionName MetroListPlace_nbsp'}).text\n",
    "        \n",
    "\n",
    "    card_info = soup_auto.find('div', {'class': 'CardInfo-ateuv'})\n",
    "\n",
    "    # записали ссылку на комплектацию\n",
    "    for a in soup_auto.find_all('a'):\n",
    "        if 'Характеристики модели' in a.text:\n",
    "            link_cpl = a.get('href')\n",
    "        \n",
    "    # извлекли сведения об автомобиле\n",
    "    avail = card_info.find('li', {'class': 'CardInfoRow CardInfoRow_availability'}).find_all('div')[1].text\n",
    "    year = card_info.find('li', {'class': 'CardInfoRow CardInfoRow_year'}).find_all('div')[1].text\n",
    "    mileage = card_info.find('li', {'class': 'CardInfoRow CardInfoRow_kmAge'}).find_all('div')[1].text\n",
    "    color = card_info.find('li', {'class': 'CardInfoRow CardInfoRow_color'}).find_all('div')[1].text\n",
    "    if card_info.find('li', {'class': 'CardInfoRow CardInfoRow_engine'}).find_all('div')[1].text.split(' / ')[2] == 'Электро':\n",
    "        eng_power, eng_power_kw, eng_type = card_info.find('li', {'class': 'CardInfoRow CardInfoRow_engine'}).find_all('div')[1].text.split(' / ')\n",
    "        eng_power_kw = int(eng_power_kw.replace('\\xa0',' ').split()[0])\n",
    "        eng_size = None\n",
    "        pow_resrv = card_info.find('li', {'class': 'CardInfoRow CardInfoRow_electricRange'}).find_all('div')[1].text.split()[0]\n",
    "    else:\n",
    "        eng_size, eng_power, eng_type = card_info.find('li', {'class': 'CardInfoRow CardInfoRow_engine'}).find_all('div')[1].text.split(' / ')\n",
    "        eng_size = float(eng_size.split()[0])\n",
    "        eng_power_kw = None\n",
    "        pow_resrv = None\n",
    "    options = card_info.find('li', {'class': 'CardInfoRow CardInfoRow_complectationOrEquipmentCount'}).find_all('div')[1].text\n",
    "    transmission = card_info.find('li', {'class': 'CardInfoRow CardInfoRow_transmission'}).find_all('div')[1].text\n",
    "    drive = card_info.find('li', {'class': 'CardInfoRow CardInfoRow_drive'}).find_all('div')[1].text\n",
    "    st_wheel= card_info.find('li', {'class': 'CardInfoRow CardInfoRow_wheel'}).find_all('div')[1].text\n",
    "    condition = card_info.find('li', {'class': 'CardInfoRow CardInfoRow_state'}).find_all('div')[1].text\n",
    "    try:\n",
    "        count_owner = card_info.find('li', {'class': 'CardInfoRow CardInfoRow_ownersCount'}).find_all('div')[1].text\n",
    "    except:\n",
    "        count_owner = None\n",
    "    try:\n",
    "        original_pts = card_info.find('li', {'class': 'CardInfoRow CardInfoRow_pts'}).find_all('div')[1].text\n",
    "    except:\n",
    "        original_pts = None\n",
    "    try:\n",
    "        customs = card_info.find('li', {'class': 'CardInfoRow CardInfoRow_customs'}).find_all('div')[1].text\n",
    "    except:\n",
    "        customs = None\n",
    "\n",
    "    # подготовили словарь для месяцев\n",
    "    dict_month = {\n",
    "        'января': 1,\n",
    "        'февраля': 2,\n",
    "        'марта': 3,\n",
    "        'апреля': 4,\n",
    "        'мая': 5,\n",
    "        'июня': 6,\n",
    "        'июля': 7,\n",
    "        'августа': 8,\n",
    "        'сентября': 9,\n",
    "        'октября': 10,\n",
    "        'ноября': 11,\n",
    "        'декабря':12\n",
    "    }\n",
    "\n",
    "    # записали данные в словарь\n",
    "    row = {\n",
    "        'url_car': url_car,\n",
    "        'car_make': car_make,\n",
    "        'car_model': car_model,\n",
    "        'car_gen': car_gen,\n",
    "        'car_type': car_type,\n",
    "        'car_compl': car_compl,\n",
    "        'ann_date': str(date(2024, dict_month[ann_date.split()[1]], int(ann_date.split()[0]))),\n",
    "        'ann_id': ann_id[2:],\n",
    "        'car_price': int(car_price[:-1]),\n",
    "        'ann_city': ann_city,\n",
    "        'link_cpl': link_cpl,\n",
    "        'avail': avail.replace('\\xa0',' '),\n",
    "        'year': int(year),\n",
    "        'mileage': int(mileage.replace('\\xa0','')[:-3]),\n",
    "        'color': color,\n",
    "        'eng_size': eng_size,\n",
    "        'eng_power': int(eng_power.replace('\\xa0',' ').split()[0]),\n",
    "        'eng_power_kw': eng_power_kw,\n",
    "        'eng_type': eng_type,\n",
    "        'pow_resrv': pow_resrv,\n",
    "        'options': options.replace('\\xa0',' '),\n",
    "        'transmission': transmission,\n",
    "        'drive': drive,\n",
    "        'st_wheel': st_wheel,\n",
    "        'condition': condition,\n",
    "        'count_owner': count_owner.replace('\\xa0',' '),\n",
    "        'original_pts': original_pts,\n",
    "        'customs': customs\n",
    "        }\n",
    "    \n",
    "    if row['link_cpl'] in list(map(lambda x: x['url_compl'], complectations)):\n",
    "\n",
    "        # добавили сведения из ранее загруженной комплектации\n",
    "        for record in complectations:\n",
    "            if row['link_cpl'] == record['url_compl']:\n",
    "                row = {**row, **record}\n",
    "    else:\n",
    "        \n",
    "        # добавили сведения из комплектации\n",
    "        record = get_complectation(row['link_cpl'])\n",
    "        complectations.append(record)\n",
    "        with open('data_comp.txt', 'a') as data_comp:\n",
    "            print(record, file=data_comp)\n",
    "        row = {**row, **record}\n",
    "    \n",
    "    # передаем словарь\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_page_makes(a, b):\n",
    "\n",
    "    # изготовили ссылку на страницу списка с объявлениями\n",
    "    url = 'https://auto.ru/catalog/cars/'\n",
    "\n",
    "    # немного подождали\n",
    "    sleep()\n",
    "\n",
    "    # сходили по ней\n",
    "    page_list = requests.get(url, headers=headers)\n",
    "\n",
    "    # построили дерево\n",
    "    soup = BeautifulSoup(page_list.content, 'html.parser')\n",
    "\n",
    "    # ищем тут CatalogFilterSearchList__hidden-stSPU\n",
    "    card_info = soup.find('div', {'class': 'CatalogFilterSearchList__hidden-stSPU'})\n",
    "\n",
    "    # нашли в нём марки авто, записали в список\n",
    "    name_makes = []\n",
    "    for link in card_info.find_all('a'):\n",
    "        if link.get('href'):\n",
    "            name_makes.append(link.get('href').split('/')[-2])\n",
    "    \n",
    "    # убрали дубли\n",
    "    name_makes = list(set(name_makes))\n",
    "    \n",
    "    # отсортировали по афавиту\n",
    "    name_makes.sort()\n",
    "\n",
    "    # оставили марки из диапазона\n",
    "    name_makes = list(filter(lambda x: (ord(x[0]) >= ord(a) and ord(x[0]) <= ord(b)) , name_makes))\n",
    "    \n",
    "    return name_makes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_page(make, p):\n",
    "    # изготовили ссылку на страницу списка с объявлениями\n",
    "    url_base = f'https://auto.ru/cars/{make}/used/'\n",
    "    if p ==1:\n",
    "        url = f'{url_base}'\n",
    "    else:\n",
    "        url = f'{url_base}?page={p}'\n",
    "\n",
    "    # немного подождали\n",
    "    sleep()\n",
    "\n",
    "    # сходили по ней\n",
    "    page_list = requests.get(url, headers=headers)\n",
    "\n",
    "    # построили дерево\n",
    "    soup = BeautifulSoup(page_list.content, 'html.parser')\n",
    "\n",
    "    # нашли в нём ссылки на авто, записали в список\n",
    "    urls = []\n",
    "    for link in soup.find_all('a'):\n",
    "        if link.get('href') != None and 'cars/used/sale' in link.get('href')  and link.get('href') not in urls:\n",
    "            urls.append(link.get('href'))\n",
    "\n",
    "    # прошли по ссылкам записали данные в список словарей\n",
    "    info = []\n",
    "    mistakes = []\n",
    "\n",
    "    # включаем счетчики\n",
    "    success = 0\n",
    "    failure = 0\n",
    "    t = tqdm(urls, desc=f'Загрузка {name_make}/{page}. Успешно: {success}. Ошибок: {failure}')\n",
    "    for link in t:\n",
    "        t.set_description(f'Загрузка {name_make}/{page}. Успешно: {success}. Ошибок: {failure}')\n",
    "        t.refresh()\n",
    "        try:\n",
    "            info.append(get_car(link))\n",
    "            success += 1\n",
    "        except:\n",
    "            print(f'Ошибка при загрузке страницы: {link}')\n",
    "            mistakes.append(link)\n",
    "            failure += 1\n",
    "\n",
    "    return info, success, failure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_page_models(name_make):\n",
    "\n",
    "    # изготовили ссылку на страницу списка с объявлениями\n",
    "    url = f'https://auto.ru/cars/{name_make}/used/'\n",
    "    \n",
    "    # немного подождали\n",
    "    sleep()\n",
    "    \n",
    "    # сходили по ней\n",
    "    page_list = requests.get(url, headers=headers)\n",
    "\n",
    "    # построили дерево\n",
    "    soup = BeautifulSoup(page_list.content, 'html.parser')\n",
    "\n",
    "    # Ищем тут CatalogModelMosaic__mosaic-VDF2l\n",
    "    model_info = soup.find('div', {'class': 'ButtonWithLoader__inner'})\n",
    "\n",
    "    # нашли в нём ссылки на авто, записали в список\n",
    "    summ = int(''.join(model_info.text.replace('\\xa0',' ').split()[1:-1]))\n",
    "        \n",
    "    return summ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_complectation(file_name):\n",
    "    complectations = []\n",
    "    with open(file_name) as data:\n",
    "        for record in data:\n",
    "            res = {}\n",
    "            for paars in record[1:-2].split(\", '\"):\n",
    "                key, value = paars.split(\"':\")\n",
    "                value = value.replace(\"'\",\"\").strip()\n",
    "                if value == 'None':\n",
    "                    value = None\n",
    "                res[key.replace(\"'\",\"\").strip()] = value\n",
    "                complectations.append(res)\n",
    "    data.close()\n",
    "    return complectations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1dcd17fb152042a1a5f1b7bd619cf4e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Загрузка b - k. Успешно: 0. Ошибок: 0:   0%|          | 0/101 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96d61f5414584cacae56208b0f32d34a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Загрузка dodge. Успешно: 0. Ошибок: 0:   0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3d355e5c4f6406b9c9c21f12beeb316",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Загрузка dodge/1. Успешно: 0. Ошибок: 0:   0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ошибка при загрузке страницы: https://auto.ru/cars/used/sale/dodge/challenger/1125848381-3f50125b/\n",
      "Ошибка при загрузке страницы: https://auto.ru/cars/used/sale/dodge/journey/1124729664-983a5de4/\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# загружаем файл с комплектациями автомобилей\n",
    "data_comp = 'data_comp.txt'\n",
    "try:\n",
    "    with open('log.txt', 'a') as log:\n",
    "        complectations = open_complectation(data_comp)\n",
    "        print(f'{datetime.date.today().isoformat()} {datetime.datetime.now().time()} Загружен файл с комплектацией {data_comp}', file=log)\n",
    "except (FileNotFoundError, PermissionError):\n",
    "    complectations = []\n",
    "    with open('log.txt', 'a') as log:\n",
    "        print(f'{datetime.date.today().isoformat()} {datetime.datetime.now().time()} Не был загружен файл с комплектацией {data_comp}', file=log)\n",
    "\n",
    "# Загружаем наименования марок автомобилей\n",
    "s_letter = 'd'\n",
    "f_letter = 'k'\n",
    "name_makes = get_page_makes(s_letter, f_letter)\n",
    "name_makes = name_makes[name_makes.index('dodge'):]\n",
    "\n",
    "# включаем счетчики\n",
    "success_all = 0\n",
    "failure_all = 0\n",
    "\n",
    "# Запускаем цикл с перебором марок автомобилей\n",
    "t_make = tqdm(name_makes, desc=f'Загрузка {s_letter} - {f_letter}. Успешно: {success_all}. Ошибок: {failure_all}')\n",
    "for name_make in t_make:\n",
    "    t_make.set_description(f'Загрузка {s_letter} - {f_letter}. Успешно: {success_all}. Ошибок: {failure_all}')\n",
    "    t_make.refresh()\n",
    "    # Вычисляем количество страниц для загрузки по марке (не более 100)\n",
    "    try:\n",
    "        count_page = get_page_models(name_make) // 38 + 2\n",
    "        count_page = min(count_page, 100)\n",
    "    except:\n",
    "        count_page = 1\n",
    "\n",
    "    # включаем счетчики\n",
    "    success_make = 0\n",
    "    failure_make = 0\n",
    "\n",
    "    # Запускаем цикл с перебором страниц марки\n",
    "    t = tqdm(range(1, count_page), desc=f'Загрузка {name_make}. Успешно: {success_make}. Ошибок: {failure_make}')\n",
    "    for page in t:\n",
    "        try:\n",
    "            t.set_description(f'Загрузка {name_make}. Успешно: {success_make}. Ошибок: {failure_make}')\n",
    "            t.refresh()\n",
    "            # Загружаем сведения об автомобиле\n",
    "            date_page = get_page(name_make, page)\n",
    "            success_make += date_page[1]\n",
    "            success_all += date_page[1]\n",
    "            failure_make += date_page[2]\n",
    "            failure_all += date_page[2]\n",
    "            with open('data.txt', 'a') as data:\n",
    "                for record in date_page[0]:\n",
    "                    print(record, file=data)\n",
    "            with open('log.txt', 'a') as log:\n",
    "                print(f'{datetime.date.today().isoformat()} {datetime.datetime.now().time()} Успешно загружена страница {name_make}/{page}. Число добавленных записей {len(date_page[0])}', file=log)\n",
    "        except:\n",
    "            with open('log.txt', 'a') as log:\n",
    "                print(f'{datetime.date.today().isoformat()} {datetime.datetime.now().time()} Не была загружена страница {name_make}/{page}. Число добавленных записей {0}', file=log)\n",
    "            \n",
    "        data.close()\n",
    "        log.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
