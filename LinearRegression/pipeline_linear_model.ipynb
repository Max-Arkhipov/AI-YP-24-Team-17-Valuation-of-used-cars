{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1258,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, PolynomialFeatures\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import r2_score, mean_squared_error as MSE, mean_absolute_error as MAE\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1259,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Фиксируем датчики случайных чисел\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Загружаем данные\n",
    "df = pd.read_csv('data_add.csv')\n",
    "\n",
    "# Разделяем ИСХОДНЫЕ ДАННЫЕ на тренировочную и тестовую выборки\n",
    "df_train, df_test = train_test_split(df, train_size=0.75, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1260,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Класс для удаления столбцов из датасета\n",
    "class columnDropperTransformer():\n",
    "    def __init__(self,columns):\n",
    "        self.columns=columns\n",
    "    def transform(self,X,y=None):\n",
    "        X = X.drop(self.columns,axis=1)\n",
    "        return X\n",
    "    def fit(self, X, y=None):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1261,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Класс для обработки типа автомобиля\n",
    "class columnCarTypeTransformer():\n",
    "    def __init__(self,columns):\n",
    "        self.columns=columns\n",
    "    def transform(self,X,y=None):\n",
    "        def mod_car_type(x):\n",
    "            car_type_short = [\n",
    "                'Внедорожник 3 дв.',\n",
    "                'Внедорожник 5 дв.',\n",
    "                'Внедорожник открытый',\n",
    "                'Кабриолет',\n",
    "                'Компактвэн',\n",
    "                'Купе',\n",
    "                'Лифтбек',\n",
    "                'Микровэн',\n",
    "                'Минивэн',\n",
    "                'Пикап Двойная кабина',\n",
    "                'Пикап Одинарная кабина',\n",
    "                'Пикап Полуторная кабина',\n",
    "                'Родстер',\n",
    "                'Седан',\n",
    "                'Спидстер',\n",
    "                'Тарга',\n",
    "                'Универсал 5 дв.',\n",
    "                'Фастбек',\n",
    "                'Фургон',\n",
    "                'Хэтчбек 3 дв.',\n",
    "                'Хэтчбек 4 дв.',\n",
    "                'Хэтчбек 5 дв.'\n",
    "            ]\n",
    "            for car_type in car_type_short:\n",
    "                if car_type in x:\n",
    "                    x = car_type\n",
    "            return x\n",
    "        X['car_type'] = X['car_type'].apply(lambda x: mod_car_type(x) if not pd.isnull(x) else np.nan)\n",
    "        return X\n",
    "    def fit(self, X, y=None):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1262,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создание класса-трансформера для заполнения пропусков медианой по группам\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Класс-трансформер для заполнения пропусков медианой по группам\n",
    "class GroupMedianImputer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, group_cols, target_col):\n",
    "        \"\"\"\n",
    "        Инициализация трансформера.\n",
    "        \n",
    "        :param group_cols: Список колонок для группировки.\n",
    "        :param target_col: Колонка с пропусками для заполнения.\n",
    "        \"\"\"\n",
    "        self.group_cols = group_cols\n",
    "        self.target_col = target_col\n",
    "        self.group_medians_ = None\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        # Рассчитываем медианы по комбинации значений в group_cols\n",
    "        self.group_medians_ = (\n",
    "            X.groupby(self.group_cols)[self.target_col]\n",
    "            .median()\n",
    "            .reset_index()\n",
    "            .rename(columns={self.target_col: \"median_value\"})\n",
    "        )\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        # Объединяем с рассчитанными медианами по ключевым столбцам\n",
    "        X = X.merge(self.group_medians_, on=self.group_cols, how=\"left\")\n",
    "        # Заполняем пропуски в целевой колонке\n",
    "        X[self.target_col] = X[self.target_col].fillna(X[\"median_value\"])\n",
    "        # Удаляем временную колонку с медианой\n",
    "        X.drop(columns=[\"median_value\"], inplace=True)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1263,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создание класса-трансформера для заполнения пропусков модой по группам\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Класс-трансформер для заполнения пропусков модой по группам\n",
    "class GroupModeImputer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, group_cols, target_col):\n",
    "        \"\"\"\n",
    "        Инициализация трансформера.\n",
    "\n",
    "        :param group_cols: Список колонок для группировки.\n",
    "        :param target_col: Колонка с пропусками для заполнения.\n",
    "        \"\"\"\n",
    "        self.group_cols = group_cols\n",
    "        self.target_col = target_col\n",
    "        self.group_modes_ = None\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        # Рассчитываем моды по комбинации значений в group_cols\n",
    "        def safe_mode(series):\n",
    "            if series.empty:\n",
    "                return np.nan\n",
    "            mode = series.mode()\n",
    "            return mode.iloc[0] if not mode.empty else np.nan\n",
    "\n",
    "        self.group_modes_ = (\n",
    "            X.groupby(self.group_cols)[self.target_col]\n",
    "            .agg(safe_mode)\n",
    "            .reset_index()\n",
    "            .rename(columns={self.target_col: \"mode_value\"})\n",
    "        )\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        # Объединяем с рассчитанными модами по ключевым столбцам\n",
    "        X = X.merge(self.group_modes_, on=self.group_cols, how=\"left\")\n",
    "        # Заполняем пропуски в целевой колонке\n",
    "        X[self.target_col] = X[self.target_col].fillna(X[\"mode_value\"])\n",
    "        # Удаляем временную колонку с модой\n",
    "        X.drop(columns=[\"mode_value\"], inplace=True)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1264,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создание класса-трансформера для замены пропусков в столбце на основе условий из другого столбца\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Класс-трансформер для замены пропусков в столбце на основе условий из другого столбца\n",
    "class ConditionalValueImputer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, condition_col, target_col, fill_mapping):\n",
    "        \"\"\"\n",
    "        Инициализация трансформера.\n",
    "\n",
    "        :param condition_col: Колонка с условиями.\n",
    "        :param target_col: Колонка, в которой будут заменяться пропуски.\n",
    "        :param fill_mapping: Словарь, где ключ - значение из condition_col, а значение - значение для замены пропусков в target_col.\n",
    "        \"\"\"\n",
    "        self.condition_col = condition_col\n",
    "        self.target_col = target_col\n",
    "        self.fill_mapping = fill_mapping\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self  # Нет необходимости обучать\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        for condition_value, fill_value in self.fill_mapping.items():\n",
    "            mask = (X[self.condition_col] == condition_value) & (X[self.target_col].isna())\n",
    "            X.loc[mask, self.target_col] = fill_value\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1265,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создание класса-трансформера для преобразования строк, начинающихся с числа, в число\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Класс-трансформер для преобразования строк, начинающихся с числа, в число\n",
    "class NumberExtractorTransformer():\n",
    "    def __init__(self, columns):\n",
    "        \"\"\"\n",
    "        Инициализация трансформера.\n",
    "\n",
    "        :param columns: Список названий столбцов, для которых нужно извлекать числа.\n",
    "        \"\"\"\n",
    "        self.columns = columns\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        \"\"\"\n",
    "        Извлекает числа из начала строки для указанных столбцов.\n",
    "\n",
    "        :param X: Входной DataFrame.\n",
    "        :param y: Не используется, добавлен для совместимости с API sklearn.\n",
    "        :return: Преобразованный DataFrame.\n",
    "        \"\"\"\n",
    "        X = X.copy()\n",
    "        for column in self.columns:\n",
    "            X[column] = (\n",
    "                X[column]\n",
    "                .astype(str)              # Преобразование в строку\n",
    "                .str.extract(r'^(\\d+)')  # Извлечение первого числа в начале строки\n",
    "                .astype(float)           # Преобразование к числовому типу\n",
    "            )\n",
    "        return X\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self  # Нет необходимости обучать"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1266,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Класс для удаления дубликатов\n",
    "class DropDuplicate:\n",
    "    def __init__(self, columns_to_exclude=None):\n",
    "        \"\"\"\n",
    "        Класс для удаления дубликатов на основе выбранных столбцов.\n",
    "\n",
    "        :param columns_to_exclude: Список столбцов, которые нужно исключить из проверки на дубликаты.\n",
    "        \"\"\"\n",
    "        self.columns_to_exclude = columns_to_exclude or []\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        \"\"\"\n",
    "        Удаляет дубликаты из DataFrame на основе заданных столбцов.\n",
    "\n",
    "        :param X: Входной DataFrame.\n",
    "        :param y: Не используется, добавлен для совместимости с API sklearn.\n",
    "        :return: DataFrame без дубликатов.\n",
    "        \"\"\"\n",
    "        X = X.copy()\n",
    "        # Определение столбцов для проверки на дубликаты\n",
    "        column_features = [col for col in X.columns if col not in self.columns_to_exclude]\n",
    "        # Удаление дубликатов\n",
    "        X = X.drop_duplicates(subset=column_features, keep='first').reset_index(drop=True)\n",
    "        return X\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self  # Нет необходимости обучать"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1267,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Класс для обновления индекса\n",
    "class resetIndex():\n",
    "\n",
    "    def transform(self,X,y=None):\n",
    "        \"\"\"\n",
    "        Класс для обновления индекса.\n",
    "        \n",
    "        :param X: Входной DataFrame.\n",
    "        :param y: Не используется, добавлен для совместимости с API sklearn.\n",
    "        :return: DataFrame с обновленным индексом.\n",
    "        \"\"\"\n",
    "        X = X.reset_index(drop=True)\n",
    "        return X\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self  # Нет необходимости обучать"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1268,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Пока пустой пайплайн для обработки полей\n",
    "pipelines = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1269,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Добавляем пайплайн для удаления полей, преобразования 'car_type' и 'count_owner', 'seat_count', 'clearence', 'v_bag', 'fuel_cons'\n",
    "drop_columns = ['Unnamed: 0', \n",
    "                'url_car', \n",
    "                'ann_id', \n",
    "                'ann_date', \n",
    "                'ann_city', \n",
    "                'avail', \n",
    "                'original_pts', \n",
    "                'customs', \n",
    "                'link_cpl', \n",
    "                'eng_power_kw', \n",
    "                'pow_resrv', \n",
    "                'options', \n",
    "                'condition', \n",
    "                'url_compl', \n",
    "                'gross_weight']\n",
    "\n",
    "pipelines.append((\"column_dropper\", columnDropperTransformer(drop_columns)))\n",
    "pipelines.append((\"car_type_transformer\", columnCarTypeTransformer('car_type')))\n",
    "pipelines.append((\"count_owner_transformer\", NumberExtractorTransformer(columns=['count_owner', 'seat_count', 'clearence', 'v_bag', 'fuel_cons'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1270,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Добавляем пайплайн для замены пропусков в классе автомобиля (\"class_auto\")\n",
    "pipelines.append((f'class_auto_transformer_car_type', ConditionalValueImputer(\n",
    "    condition_col='car_type',\n",
    "    target_col='class_auto',\n",
    "    fill_mapping={\n",
    "        'Фургон': 'M',  # Для фургонов заполняем 'M'\n",
    "        'Лимузин': 'F',  # Для лимузинов заполняем 'F'\n",
    "        }\n",
    "    )),\n",
    "    )\n",
    "\n",
    "strategy = [['car_make', 'car_model', 'car_gen', 'eng_type'], \n",
    "            ['car_make', 'car_model', 'car_gen'], \n",
    "            ['car_make', 'car_model', 'eng_type'],\n",
    "            ['car_make', 'car_model'],\n",
    "            ['car_type', 'eng_type'], \n",
    "            ['car_type']\n",
    "            ]\n",
    "\n",
    "target_columns = ['class_auto']\n",
    "\n",
    "for target_column in target_columns:\n",
    "    for columns in strategy:\n",
    "        pipelines.append(((f'group_mean_imputer_{target_column}_{columns}', GroupModeImputer(group_cols=columns, target_col=target_column))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1271,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Добавляем пайплайн для замены пропусков в числовых полях для электрокаров\n",
    "target_columns = ['eng_size', 'v_tank', 'fuel_cons', 'cyl_count']\n",
    "\n",
    "for target_column in target_columns:\n",
    "    pipelines.append((f'eng_type_elektro_transformer_{target_column}', ConditionalValueImputer(\n",
    "        condition_col='eng_type',\n",
    "        target_col=target_column,\n",
    "        fill_mapping={\n",
    "            'Электро': 0,  # Для электрокаров заполняем 0\n",
    "            }\n",
    "        )),\n",
    "        )\n",
    "    \n",
    "# Добавляем пайплайн для замены пропусков в текстовых полях для электрокаров\n",
    "target_columns = ['fuel_brand', 'engine_loc1', 'engine_loc2', 'turbocharg']\n",
    "\n",
    "for target_column in target_columns:\n",
    "    pipelines.append((f'eng_type_elektro_transformer_{target_column}', ConditionalValueImputer(\n",
    "        condition_col='eng_type',\n",
    "        target_col=target_column,\n",
    "        fill_mapping={\n",
    "            'Электро': 'Nan',  # Для электрокаров заполняем 'Nan'\n",
    "            }\n",
    "        )),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1272,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Добавляем пайплайн для замены пропусков в числовых полях медианой\n",
    "strategy = [['car_make', 'car_model', 'car_gen', 'eng_type'], \n",
    "            ['car_make', 'car_model', 'car_gen'], \n",
    "            ['car_make', 'car_model', 'eng_type'],\n",
    "            ['car_make', 'car_model'],\n",
    "            ['car_type', 'class_auto', 'eng_type'], \n",
    "            ['car_type', 'class_auto'],\n",
    "            ['car_type', 'eng_type'], \n",
    "            ['car_type'],\n",
    "            ['class_auto', 'eng_type'],\n",
    "            ['class_auto']\n",
    "            ]\n",
    "\n",
    "target_columns = ['clearence', \n",
    "                  'v_bag', \n",
    "                  'v_tank', \n",
    "                  'curb_weight', \n",
    "                  'max_speed', \n",
    "                  'acceleration', \n",
    "                  'fuel_cons', \n",
    "                  'max_torq']\n",
    "\n",
    "for target_column in target_columns:\n",
    "    for columns in strategy:\n",
    "        pipelines.append(((f'group_median_imputer_{target_column}_{columns}', GroupMedianImputer(group_cols=columns, target_col=target_column))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1273,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Добавляем пайплайн для замены пропусков в категориальных полях модой\n",
    "strategy = [['car_make', 'car_model', 'car_gen', 'eng_type'], \n",
    "            ['car_make', 'car_model', 'car_gen'], \n",
    "            ['car_make', 'car_model', 'eng_type'],\n",
    "            ['car_make', 'car_model'],\n",
    "            ['car_type', 'class_auto', 'eng_type'], \n",
    "            ['car_type', 'class_auto'],\n",
    "            ['car_type', 'eng_type'], \n",
    "            ['car_type'],\n",
    "            ['class_auto', 'eng_type'],\n",
    "            ['class_auto']\n",
    "            ]\n",
    "\n",
    "target_columns = ['rear_brakes',\n",
    "                  'max_speed',\n",
    "                  'fuel_brand',\n",
    "                  'engine_loc1',\n",
    "                  'engine_loc2',\n",
    "                  'turbocharg']\n",
    "\n",
    "for target_column in target_columns:\n",
    "    for columns in strategy:\n",
    "        pipelines.append(((f'group_moda_imputer_{target_column}_{columns}', GroupModeImputer(group_cols=columns, target_col=target_column))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1274,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Добавляем пайплайн для удаления полей, преобразования car_type и count_owner\n",
    "drop_columns = ['car_model', 'car_gen', 'car_compl']\n",
    "\n",
    "pipelines.append((\"column_dropper_transformer\", columnDropperTransformer(drop_columns)))\n",
    "pipelines.append((\"drop_duplicate\", DropDuplicate()))\n",
    "pipelines.append((\"reset_index\", resetIndex()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1275,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаем пайплайн\n",
    "pipeline = Pipeline(steps=pipelines)\n",
    "\n",
    "# Обучение Pipeline\n",
    "transformed_train = pipeline.fit_transform(df_train)\n",
    "\n",
    "# Преобразование тестовых данных\n",
    "transformed_test = pipeline.transform(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1276,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Преобразуем и разделяем признаки и таргет\n",
    "X_train = transformed_train.copy()\n",
    "y_train = np.log(transformed_train['car_price'])\n",
    "X_test = transformed_test.copy()\n",
    "y_test = np.log(transformed_test['car_price'])\n",
    "X_train = X_train.drop(['car_price'], axis=1)\n",
    "X_test = X_test.drop(['car_price'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1277,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/preprocessing/_encoders.py:242: UserWarning: Found unknown categories in columns [0, 1, 7] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Собственно, наш пайплайн\n",
    "cat_features_mask = (X_train.dtypes == \"object\").values\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('onehot', OneHotEncoder(drop='first', min_frequency=4, max_categories=140, handle_unknown='ignore'))  # OHE-кодирование\n",
    "])\n",
    "\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('poly', PolynomialFeatures(degree=2)), # Poly-кодирование\n",
    "    ('scaler', StandardScaler()) # Стандартизируем\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', categorical_transformer, X_train.columns[cat_features_mask]), # Обрабатываем категориальные признаки\n",
    "        ('num', numerical_transformer, X_train.columns[~cat_features_mask]) # Обрабатываем числовые признаки\n",
    "    ]\n",
    ")\n",
    "\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', Ridge(alpha=8.3)) # Используем Ridge\n",
    "])\n",
    "\n",
    "pipeline.fit(X_train, y_train) # Обучаем модель\n",
    "\n",
    "y_pred = pipeline.predict(X_test) # Создаем переменные для вывода результатов\n",
    "y_pred_train = pipeline.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1278,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция вывода основных характеристик модели (ориентируемся прежде всего на R^2)\n",
    "def print_r2_mse(y_train, y_test, y_pred):\n",
    "    '''\n",
    "    Функция принимает на вход признаки и таргет для тренировочных\n",
    "    и тестовых данных, модель и выводит на экран \n",
    "    значения MSE, R^2 для трейна и теста для указанных параметров\n",
    "    '''\n",
    "    print('*'*20)\n",
    "    print(f'Значение MAE для трейна:  {MAE(np.exp(y_train), np.exp(y_pred_train))}')\n",
    "    print(f'Значение MAE для теста:   {MAE(np.exp(y_test), np.exp(y_pred))}')\n",
    "    print('*'*20)\n",
    "    print(f'Значение MSE для трейна:  {MSE(np.exp(y_train), np.exp(y_pred_train))}')\n",
    "    print(f'Значение MSE для теста:   {MSE(np.exp(y_test), np.exp(y_pred))}')\n",
    "    print('*'*20)\n",
    "    print(f'Значение R^2 для трейна:  {r2_score(y_train, y_pred_train)}')\n",
    "    print(f'Значение R^2 для теста:   {r2_score(y_test, y_pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************\n",
      "Значение MAE для трейна:  535513.879650517\n",
      "Значение MAE для теста:   526495.6193577688\n",
      "********************\n",
      "Значение MSE для трейна:  13549270210128.273\n",
      "Значение MSE для теста:   11724703980847.072\n",
      "********************\n",
      "Значение R^2 для трейна:  0.9195606507181248\n",
      "Значение R^2 для теста:   0.9181117026132478\n"
     ]
    }
   ],
   "source": [
    "print_r2_mse(y_train, y_test, y_pred) # Выводим результаты, довольны собой"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
